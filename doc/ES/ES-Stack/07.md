```
+++
author = "kmplex"
title = "ELK Stack 개발부터 운영까지 7장"
date = "2022-04-04"
description = "Elastic Search 7장"
series = ["ES"]
categories = ["dev"]
+++
```

# Beats 

Beats 는 가볍고 사용하기 쉬운 데이터 수집기이다. Go Lang 으로 작성된 프로그램이기때문에 로그 수집을 원하는 시스템에 큰 부담을 주지 않는다.
또한 logstash 와 ES 등과 연계하여 다양한 시스템의 이벤트를 수집 할 수 있게 도와준다.
Filebeat 뿐 아니라 metricbeat, packetbeat, winlogbeat 등 다양한 beat 가 존재하며, 온프레미스 / 가상 머신 / 쿠버네티스 환경에서도 사용이 가능하다.

## Beats 소개 

비츠는 가벼운 프로그램을 지향하기에, 하나의 목적만을 수행하며 각 목적에 맞는 비츠들이 존재한다.
데이터 수집하는 역할만을 보면 logstash 와 비슷해보이지만, 비츠는 범용성을 포기하고 특정 목적만 수행하도록 가볍게 구성되어,
Application 의 성능에 영향을 미치지 않고 필요한 이벤트를 수집 할 수 있다.

> 이벤트 가공을 완전히 지원하지 않는건 아니라서, 간단한 수집이라면 비츠를 쓰는게 성능상 유리하다.

다만, 전문적이고 범용적인 대량 이벤트 가공이 필요하다면, logstash가 더 적합하다.
그러므로, 비츠는 logstash 의 대체재라기보단 공생 관계로 이해하자.

일반적으로 비츠에서 수집한 데이터는 ES 로 보내거나, logstash 를 거쳐 ES 로 보내진다.

> logstash 를 거칠 경우, 비트에서 발생된 다량의 이벤트들을 일괄적으로 가공 / 처리할 수 있다. 
> 발생량이 많지 않거나, 복잡한 가공을 수행할 필요가 없다면 logstash 를 거치지 않아도 무방하다.

## 파일비트 

서버나 시스템을 운영하다 보면, 수많은 로그들이 파일 형태로 발생한다. 이러한 로그 파일을 쉽게 수집할 수 있도록 도와준다.
앞서 말했듯, Go lang 으로 작성되어 가볍기때문에 수집할 시스템에 부담없이 설치될 수 잇다.

파일비트는 크게 세가지 구성요소로 이루어져있다.

1. 입력 
- 하베스터에 대한 입력 소스를 정한다. 하나 혹은 여러개의 입력을 가질 수 있다.
2. 하베스터 (harvester) 
- 입력에 명시된 파일을 직접 수집하는 주체다. 파일은 하나의 하베스트를 가지며 파일을 한줄씩 읽고 내보내는 역할을 한다. 
- 하베스터가 실행되는 동안 파일 디스크립터가 열려있다. 
3. 스풀러 (spooler)
- 하베스터가 수집한 이벤트를 ES / Logstash 같은 장소로 전달한다.

파일비트는 기본적으로 파일에 적재되는 로그들을 가져오는 역할을 한다.
입력에서 대상 경로를 모니터링하다가, 새로운 파일이 발견되면 하베스터를 생성해서 해당 데이터를 읽어 들인다.

## 실행 

filebeat.yml 이라는 설정파일로 beat 의 설정을 수정할 수 있다.

> ${bit 종류}beat.yml 형태로 설정파일이 존재한다. ex) heartbeat.yml / metricbeat.yml 
> 또한 filebeat.reference.yml 파일에 모든 설정에 대한 설명 / 기본 값이 적혀져 있다.

```text
# ============================== Filebeat inputs ===============================

filebeat.inputs:
- type: filestream
  enabled: false
  paths:
    - /var/log/*.log
    
output.elasticsearch:
  host: ["localhost:9200"]
setup.kibana:
  host: "localhost:5601"
```

`input` 은 파일비츠가 가져오는 입력이고, `output` 은 내보내는 출력이다. 

파일비트의 인풋 타입은 아래와 같다.

- log  
  - 가장 기본이 되는 타입으로, 파일시스템의 지정한 경로에서 로그파일을 읽어 들인다.
- container
  - 도커 같은 컨테이너의 로그를 수집하기 위한 입력으로, 파일을 읽어 들인다는 점에서 log 와 유사하다.
- s3
  - 아마존 웹 서비스의 s3 버킷에 위치한 파일을 읽어들인다.
- kafka
  - 카프카의 토픽을 읽어 들인다.

`output`은 하베스터가 읽어들인 데이터를 전달할 곳으로, 아웃풋 타입은 아래와 같다.

- elasticsearch
- logstash
  - 인덱싱 리퀘스트 양이 많거나, 복잡한 가공 작업이 필요할때, logstash를 구축하여 이벤트를 전송한다.
  - 다수 인덱싱 요청이 logstash 에서 단일 벌크 리퀘스트로 묶여 indexing 효율의 개선을 기대할 수 있다.
- kafka
  - 큐 수집 중 장애 발생 시, 데이터 손실을 최소화하기 위한 방안으로 활용된다. 
- console 
  - 주로 테스트 용도로 사용된다.


`setup.kibana`을 사용할 경우,  키바나 대시보드에서 파일비트 데이터를 확인 할 수 있다.

## 유용한 설정 

`ignore_older` 는 새로운 파일 탐색 시, 오래된 파일은 읽어 들이지 않고 무시하기 위한 설정이다.
인풋 타입이 log 인 경우 사용할 수 있는 옵션으로, 10h, 10m 처럼 타임스트링 형식으로 작성한다.

`ignore_older: 24h` 같이 작성하면, 24시간 전의 로그만 수집하겠다는 의미이다.
기본 값은 0으로, 특별히 값을 명시하지 않으면, 생성 / 수정 시간과 무관하게 모든 내용을 읽어 들인다.

`include_lines` 와 `exclude_lines`은 특정 라인을 추가/ 제외하는 옵션이다.
복잡한 정제 작업을 수행할 수는 없지만, 간단한 정제 작업을 비츠에서 처리하면, ES / logstash 에서 처리하는 작업량을 줄일 수 있다.

정규식 표현을 이용해, 매칭된 라인을 수집 혹은 제외할 수 있으며, 아래와 같이 사용할 수 있다.

```
include_lines: ['^ERR', '^WARN']
exclude_lines: ['^DBG']
```

line 뿐 아니라  file 이름으로도 제외 할 수 있다.

```
exclude_files: ['\.gz$']
```

만약 log 가 여러줄에 걸쳐 나온다면, multi-line 옵션을 사용할 수 있다.

```
multiline.pattern: '^[[:space:]]'
multiline.negate: false 
multiline.match: after
```

- `multiline.pattern` 은 정규식을 이용하여 패턴을 지정한다. 패턴과 일치하는 라인이 나타나면 멀티라인으로 인식한다.
- `multiline.negate` 패턴의 일치 조건을 반전 시킨다. true 일 경우, 공백이 아닐때 multi-line 으로 인지한다. 
- `multiline.match` 는 multi-line 을 처리하는 방식으로, before 와 after 로 지정할 수 있다.
  - 공백으로 시작하는 라인을 공백으로 시작하지 않는 라인 뒤에 붙이게 된다.

> 예제 파일 

```text
aoo
koo
boo
boo
zoo
boo
```

> 1번 설정 

```text
multiline.pattern: '^b'
multiline.negate: false 
multiline.match: after
```

위 설정은 첫번째 문자가 b 로 시작하는 경우 패턴으로 인식하며, negate 가 false 이므로 설정을 반전시키지 않는다.
또한 match 가 after 이므로, b로 시작하는 문자들을 이전 문자 뒤에 붙인다.

```text
1. koo boo boo
2. zoo boo 
```

> 2번 설정

```text
multiline.pattern: '^b'
multiline.negate: false 
multiline.match: before 
```

위 예제에서 match 가 before 로 바뀌었는데, b 로 시작하는 문자들이 먼저오고, 다음 라인의 문자열을 붙이게 된다.

```text
boo boo zoo
boo 
```

> 3번 설정

```text
multiline.pattern: '^b'
multiline.negate: true
multiline.match: after
```

match 는 after 이며, negate 가 true 일 경우, b로 시작하지 않는 문자열을 뒤로 붙이게된다.
`after` 설정은 패턴에 맞는 라인이 있고, 그 앞에 패턴이 일치하지 않는 라인이 있을때 멀티라인을 구성한다.

즉, aoo / koo 는 앞에 일치하지 않는 라인이 없기때문에 버려지고, 아래와 같은 결과만이 출력된다.

```text
boo
boo zoo 
boo
```

> 4번 설정 

```text
multiline.pattern: '^b'
multiline.negate: true
multiline.match: before 
```

> 2번째 친구는 왜 출력되는거지 살짝 이해가 안감 

```
aoo koo boo
boo (?)  
zoo boo
```

## 모듈 

모듈이란 많이 사용되는 시스템 데이터를 수집하기 위해, 일반적인 설정을 사전 정의해준 것이다.

> 손쉽게 사용 할 수 있도록 모듈화해두었다.

파일비트는 아래와 같은 모듈을 지원한다.

- aws  / cef / cisco / elasticsearch / googlecloud / logstash

모듈을 설치받은 후, 아래처럼 사용하면 된다.

```text
filebeat.config.modules:
  path: ${path.config}/modules.d/*.yml
```

위처럼 설정 후, console 을 통해, 모듈을 활성화 할 수 있다.
